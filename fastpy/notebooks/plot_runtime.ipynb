{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from context import fastpy\n",
    "from fastpy.io.output_loader import OutputParser\n",
    "from fastpy.evaluation import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all possible combinations (algos, obj funcs) from one fastpy benchmark run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If use_most_recent=True (defulat), no matter whether a run_name is given or not, the most recent run is being loaded\n",
    "out_parser = OutputParser()\n",
    "\n",
    "# plot_types: 'performance', 'mean_runtime'\n",
    "_ = plotting.plot_mean_runtime_vs_input_size(out_parser, plot_type='mean_runtime')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot over different fastpy runs \n",
    "Here we can compare the same runs over say different executables (releases)  \n",
    "(only one algo / one obj func allowed per config and configs must match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DICT = {'enhance-data': 'run_2019-05-21_09-06-56-319657',\n",
    "            'ver0.0.6': 'run_2019-05-21_08-58-31-749510',\n",
    "            'ver0.0.5': 'run_2019-05-21_08-58-58-676734',\n",
    "            'ver0.0.4': 'run_2019-05-21_08-59-21-804721',\n",
    "            'ver0.0.3': 'run_2019-05-21_08-59-45-790868',\n",
    "            'ver0.0.2': 'run_2019-05-21_09-01-29-447863',\n",
    "            'ver0.0.1': 'run_2019-05-21_09-00-42-830179'}\n",
    "\n",
    "COLOR_MAP = 'cool'\n",
    "\n",
    "out_parser_dict = plotting.prepare_multiple_out_parsers(RUN_DICT)\n",
    "plotting.mult_plot_runtime_performance(out_parser_dict, plot_type='performance', colormap=COLOR_MAP, reverse_legend=False)\n",
    "plotting.mult_plot_runtime_performance(out_parser_dict, plot_type='mean_runtime', colormap=COLOR_MAP, reverse_legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastpy",
   "language": "python",
   "name": "fastpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
